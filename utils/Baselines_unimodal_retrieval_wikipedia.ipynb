{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "#my libraries\n",
    "src_path = 'path_to_src'\n",
    "datar = 'path_to_data'\n",
    "# add src_path if it's located in another path\n",
    "#sys.path.append(os.path.join(src_path,'multimodal_retrieval/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to compute average precision for retrieval given other samples as inputs\n",
    "def get_AP(sorted_scores, given_sample, top_k, GT_samples):\n",
    "        consider_top = sorted_scores[:top_k]\n",
    "        top_sample_classes = [GT_samples[i[0]] for i in consider_top]\n",
    "        class_of_sample = GT_samples[given_sample]\n",
    "        T = top_sample_classes.count(class_of_sample)\n",
    "        R = top_k\n",
    "        sum_term = 0\n",
    "        for i in range(0,R):\n",
    "                if top_sample_classes[i] != class_of_sample:\n",
    "                        pass\n",
    "                else:\n",
    "                        p_r = top_sample_classes[:i+1].count(class_of_sample)\n",
    "                        sum_term = sum_term + (p_r*1.0)/len(top_sample_classes[:i+1])\n",
    "        if T == 0:\n",
    "                return 0\n",
    "        else:\n",
    "                return float(sum_term/T)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n"
     ]
    }
   ],
   "source": [
    "# Read the required Ground truth for the task - IMAGES\n",
    "keys = os.path.join(datar,'datasets/wikipedia/testset_txt_img_cat.list')\n",
    "im_txt_pair_wd = open(keys, 'r').readlines()\n",
    "GT_samples = {} # In general\n",
    "for i in im_txt_pair_wd:\n",
    "    GT_samples[i.split('\\t')[1]] = i.split('\\t')[2].replace('\\n','') # (Corresponding image, class)  \n",
    "print(len(GT_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# reading resnet101 features \n",
    "data_f = os.path.join(datar,'datasets/wikipedia/gen','resnet_all.pkl')\n",
    "with open(data_f,'rb') as f:\n",
    "    images = pickle.load(f)\n",
    "\n",
    "images_f = {}\n",
    "for img_id,cl in GT_samples.items():\n",
    "    try:        \n",
    "        images_f[img_id] = images.get(img_id).squeeze()\n",
    "    except Exception as e:\n",
    "        print ('CORRUPTED IMAGE: ',img_id)\n",
    "        print('Exception: %s',\"\".join(traceback.format_exception(*sys.exc_info())))\n",
    "len(images_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n"
     ]
    }
   ],
   "source": [
    "# Read the required Ground truth for the task - TEXT\n",
    "keys = os.path.join(datar,'datasets/wikipedia/testset_txt_img_cat.list')\n",
    "im_txt_pair_wd = open(keys, 'r').readlines()\n",
    "GT_samples = {} # In general\n",
    "for i in im_txt_pair_wd:\n",
    "    GT_samples[i.split('\\t')[0]] = i.split('\\t')[2].replace('\\n','') # (Corresponding text, class)  \n",
    "print(len(GT_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# reading resnet101 features\n",
    "data_f = os.path.join(datar,'datasets/wikipedia/gen/test_bert.pkl')\n",
    "with open(data_f,'rb') as f:\n",
    "    texts = pickle.load(f)\n",
    "len(texts)\n",
    "\n",
    "texts_f = {}\n",
    "for s_id,cl in GT_samples.items():\n",
    "    try:        \n",
    "        texts_f[s_id] = texts.get(s_id)[0]\n",
    "    except Exception as e:\n",
    "        print ('CORRUPTED Text: ',s_id)\n",
    "        print('Exception: %s',\"\".join(traceback.format_exception(*sys.exc_info())))\n",
    "len(texts_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1386\n"
     ]
    }
   ],
   "source": [
    "keys = os.path.join(datar,'datasets/wikipedia/testset_txt_img_cat.list')\n",
    "im_txt_pair_wd = open(keys, 'r').readlines()\n",
    "GT_samples = {} # In general\n",
    "for i in im_txt_pair_wd:\n",
    "    GT_samples[i.split('\\t')[1]] = i.split('\\t')[2].replace('\\n','') # (Corresponding image, class)  \n",
    "    GT_samples[i.split('\\t')[0]] = i.split('\\t')[2].replace('\\n','') # (Corresponding text, class)  \n",
    "print(len(GT_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>distances</th>\n",
       "      <th>8</th>\n",
       "      <th>50</th>\n",
       "      <th>500</th>\n",
       "      <th>692</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img2img</td>\n",
       "      <td>corr</td>\n",
       "      <td>0.448019</td>\n",
       "      <td>0.331130</td>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.195581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2img</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.433935</td>\n",
       "      <td>0.323024</td>\n",
       "      <td>0.193828</td>\n",
       "      <td>0.180504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img2img</td>\n",
       "      <td>cos</td>\n",
       "      <td>0.140580</td>\n",
       "      <td>0.130297</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>0.098422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt2txt</td>\n",
       "      <td>corr</td>\n",
       "      <td>0.732741</td>\n",
       "      <td>0.594859</td>\n",
       "      <td>0.402484</td>\n",
       "      <td>0.382778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt2txt</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.735880</td>\n",
       "      <td>0.600428</td>\n",
       "      <td>0.406017</td>\n",
       "      <td>0.387331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txt2txt</td>\n",
       "      <td>cos</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>0.059512</td>\n",
       "      <td>0.059135</td>\n",
       "      <td>0.078817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task distances         8        50       500       692\n",
       "0  img2img      corr  0.448019  0.331130  0.205979  0.195581\n",
       "1  img2img        eu  0.433935  0.323024  0.193828  0.180504\n",
       "2  img2img       cos  0.140580  0.130297  0.092877  0.098422\n",
       "0  txt2txt      corr  0.732741  0.594859  0.402484  0.382778\n",
       "1  txt2txt        eu  0.735880  0.600428  0.406017  0.387331\n",
       "2  txt2txt       cos  0.068883  0.059512  0.059135  0.078817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/multimodal_retrieval/')\n",
    "from evaluation import eval_wiki_retrieval2 as eval_r\n",
    "\n",
    "distances = ['corr','eu','cos']\n",
    "topks = [8,50,500,692]  \n",
    "\n",
    "maps1 = eval_r.calc_distances(images_f,images_f,'img2img',topks,distances,GT_samples)\n",
    "maps2 = eval_r.calc_distances(texts_f,texts_f,'txt2txt',topks,distances,GT_samples)\n",
    "mapt_uni = pd.concat([maps1, maps2], axis=0)\n",
    "mapt_uni = mapt_uni[['task','distances']+topks]\n",
    "mapt_uni"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
